#!/bin/bash

#########################################################
#
# Platform: NCI Gadi HPC
#
# Author: Tracy Chew
# tracy.chew@sydney.edu.au
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
#
#########################################################

# General guide: Use resources below for ~100 FASTQ files
# ~15 M reads per FASTQ file
# walltime=01:30:00,ncpus=48,mem=190GB,wd
# Multiply walltime or number of CPUs according to fastq number/size
# fastQC efficiency ~0.9 - 1

#PBS -P bt64
#PBS -N fastqc_trimmed
#PBS -l walltime=04:00:00,ncpus=48,mem=190GB,wd
#PBS -q normal
#PBS -W umask=022
#PBS -l storage=scratch/bt64
#PBS -o ./Logs/fastqc_trimmed.o
#PBS -e ./Logs/fastqc_trimmed.e

set -e

# Set the PBS_O_WORKDIR to the scripts directory where the jobs are being queued from
PBS_O_WORKDIR=/scratch/bt64/nn8573/eqtl/ceph/RNASeq-DE/Scripts
cd "${PBS_O_WORKDIR}"

module load openmpi/4.1.0
module load nci-parallel/1.0.0a
module load fastqc/0.11.7

mkdir -p ./Logs

# NCPUS per task
NCPUS=1

INPUTS=./Inputs/fastqc_trimmed.inputs
SCRIPT=./fastqc.sh

#########################################################
# Do not edit below this line
#########################################################

M=$(( PBS_NCI_NCPUS_PER_NODE / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / PBS_NCI_NCPUS_PER_NODE)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
