#!/bin/bash

set -e

#########################################################
#
# Platform: NCI Gadi HPC
#
# Author: Tracy Chew
# tracy.chew@sydney.edu.au
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
#
#########################################################

# Description: Runs bam_stat.sh in parallel. bam_stat.sh uses
# RSeQC's bam_stat.py to collect a summary of stats on a BAM file.
# See http://rseqc.sourceforge.net/

#PBS -P bt64
#PBS -N bam_stat
#PBS -l walltime=04:00:00,ncpus=112,mem=512GB,wd
#PBS -q normalbw
#PBS -W umask=022
#PBS -l storage=scratch/bt64
#PBS -o ./Logs/bam_stat.o
#PBS -e ./Logs/bam_stat.e

# Set the PBS working directory to script directory where jobs are queued
PBS_O_WORKDIR=/scratch/bt64/nn8573/test_dir/RNASeq-DE/Scripts
cd ${PBS_O_WORKDIR}

module load openmpi/4.0.2
module load nci-parallel/1.0.0a

mkdir -p ./Logs

# NCPUS per task
NCPUS=1

SCRIPT=./bam_stat.sh
INPUTS=./Inputs/bam_stat.inputs

#########################################################
# Do not edit below this line
#########################################################

M=$(( PBS_NCI_NCPUS_PER_NODE / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / PBS_NCI_NCPUS_PER_NODE)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
