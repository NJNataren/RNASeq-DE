#!/bin/bash

#########################################################
#
# Platform: NCI Gadi HPC
#
# Author: Tracy Chew
# tracy.chew@sydney.edu.au
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
#
#########################################################

# Quite variable depending on BAM size
# Future - run each BAM as an independant job
# Could also try order inputs by BAM size (descending)

#PBS -P bt64
#PBS -N htseq-count
#PBS -l walltime=30:00:00,ncpus=240,mem=950GB,wd
#PBS -q normal
#PBS -W umask=022
#PBS -l storage=scratch/bt64
#PBS -o ./Logs/htseq-count.o
#PBS -e ./Logs/htseq-count.e

# Set the PBS_O_WORKDIR to the scripts directory where the jobs are being queued from
PBS_O_WORKDIR=/scratch/bt64/nn8573/etql/ceph/RNASeq-DE/Scripts
cd "${PBS_O_WORKDIR}"

# The htseq package is in the rnaseq-de conda bin, so thats the env we export
export PATH=$HOME/miniconda3/bin:$PATH
# Then activate the environment
source activate rnaseq-de

module load openmpi/4.1.0
module load nci-parallel/1.0.0a


mkdir -p ./Logs

# NCPUS per task
NCPUS=1

SCRIPT=./htseq-count.sh
INPUTS=./Inputs/htseq-count.inputs

#########################################################
# Do not edit below this line
#########################################################

M=$(( PBS_NCI_NCPUS_PER_NODE / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / PBS_NCI_NCPUS_PER_NODE)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
